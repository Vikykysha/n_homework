{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает\n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn (это возможно, так как мы реализуем только малую часть функциональности)\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала так же или качественнее, чем у дерева из sklearn\n",
    "5. Применить реализованное дерево решений для задачи Titanic на kaggle. Применить для той же задачи дерево решений из sklearn. Применить кросс-валидацию для подбора параметров. Сравнить с результатами предыдущих моделей. Если результат улучшился - сделать сабмит. Написать отчет о результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier(BaseEstimator, ClassifierMixin):\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2,max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.criterion = criterion\n",
    "        self.max_features = max_features\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "    @staticmethod\n",
    "    def __gini( l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        \n",
    "        imp_left =(1 - ((l_c / r_c) ** 2).sum(axis=1)).reshape(-1,1)\n",
    "        imp_right =(1 - ((r_c / r_s) ** 2).sum(axis=1)).reshape(-1,1) \n",
    "        \n",
    "        total_s = l_s + r_s\n",
    "        return imp_left * (l_s / total_s) + imp_right * (r_s / total_s)\n",
    "    @staticmethod\n",
    "    def __entropy( l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        p_l = l_c / l_s\n",
    "        p_r = r_c / r_s\n",
    "        \n",
    "        imp_left = (- np.nansum(p_l * np.log2(p_l),axis=1)).reshape(-1,1)\n",
    "        imp_right = (- np.nansum(p_r * np.log2(p_r),axis=1)).reshape(-1,1)\n",
    "        \n",
    "        total_s = l_s + r_s\n",
    "        return imp_left * (l_s / total_s) + imp_right * (r_s / total_s) \n",
    "    @staticmethod\n",
    "    def __misclass(l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "\n",
    "        p_l = (l_c / l_s).max(axis=1)\n",
    "        p_r = (r_c / r_s).max(axis=1)\n",
    "        \n",
    "        imp_left = (1 - p_l).reshape(-1,1)\n",
    "        imp_right = (1 - p_r).reshape(-1,1)\n",
    "\n",
    "        total_s = l_s + r_s\n",
    "\n",
    "        #imp_left * (l_s / total_s) + imp_right * (r_s / total_s)\n",
    "        return imp_left * (l_s / total_s) + imp_right * (r_s / total_s)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        max_features = max(1, int(np.sqrt(n_feature)))\n",
    "        return feature_ids[:max_features]\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        max_features = max(1, int(np.log2(n_feature)))\n",
    "        return feature_ids[:max_features]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return list(range(n_feature))\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Что делает этот блок кода?\n",
    "        #Сортировка признака и таргета по возрастанию признака\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        #Количество уникальных классов таргета\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        #Подготавливаем данные для разбиения. Учитываем ограничения на минимание количество сэмплов, необходимое для разграничения\n",
    "        splitted_sorted_y = sorted_y[self.min_samples_split:-self.min_samples_split]\n",
    "        #Определяем места, где меняется класс. Потом добавляем min_samples_split, чтобы сохранить исходные границы в первоначальном массиве\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "        \n",
    "        #Если класс не меняет свои значения, то не делаем ничего\n",
    "        if len(r_border_ids) == 0:\n",
    "            return float('+inf'), None\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        #считаем какое количество элементов в каждой подгруппе, где меняется признак\n",
    "        eq_el_count = r_border_ids - np.append([self.min_samples_split], r_border_ids[:-1])\n",
    "        #создаем массив-маску где количество строк - это количество мест в массиве, где меняется класс, а количество столбов - это количество классов\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        #ставим метки,показывающие, что  в этом месте, до того как класс поменялся, был этот класс. То есть, если при первом изменении класса до этого шел класс 0, то в one_hot_code[0][0] будет 1, а на one_hot_code[0][0] будет 0 \n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        #с помощью ранее посчитннаго количество элементов класса до каждого смены класса, мы перемножаем два массива, в итоге получаем маску, которая показывает сколько элементов заданного класса было в каждой из мест-подгрупп смен классов\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        #чтобы учесть еще, что мы дополнительно резервировали место под min_samples_split, и там также стоят элементы класса, мы в 0 позиию маски также прибавляем количество элементов каждого из класса в min_samples_split в \n",
    "        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:self.min_samples_split], minlength=class_number)\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        #считает количество элементов каждого из класса кумулятивно при в каждой подгруппе смены класса. Значения считаются слева, то есть при каждой смены класса считает, сколько элементов класса было до\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)    \n",
    "        #то же, только теперь считает сколько элементов класса было после\n",
    "        r_class_count = np.bincount(y) - l_class_count\n",
    "        #размеры подгрупп смен класса слева\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        #тоже только справа\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # передает полученные разбиения функции, которая подсчитает меру разнородности для каждого из разбиений и вычисляем индекс для разбиения с наименьшим значением функции\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        # возвращаем минимальное значение функции G_function и среднее значение признака на границе разбиения\n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "    \n",
    "    def __make_leaf(self, top_label, prob):       \n",
    "        return (\n",
    "            self.LEAF_TYPE, \n",
    "            top_label,\n",
    "            prob\n",
    "        )\n",
    "    \n",
    "    def __make_non_leaf(self, feature_id, threshold):       \n",
    "        return (\n",
    "            self.NON_LEAF_TYPE, \n",
    "            feature_id,\n",
    "            threshold\n",
    "        )\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        \n",
    "        label, cnt = np.unique(y, return_counts=True)\n",
    "        idx = np.argmax(cnt)\n",
    "        top_label = label[idx]\n",
    "        top_cnt = cnt[idx]\n",
    "        prob = (cnt/cnt.sum())[idx]\n",
    "\n",
    "        if depth == self.max_depth:\n",
    "            self.tree[node_id] = self.__make_leaf( top_label, prob)\n",
    "            return\n",
    "\n",
    "        if len(y) < self.min_samples_split:\n",
    "            self.tree[node_id] = self.__make_leaf(top_label, prob)\n",
    "            return\n",
    "        \n",
    "        if len(np.unique(y)) == 1:\n",
    "            self.tree[node_id] = self.__make_leaf(top_label, prob)\n",
    "            return\n",
    "\n",
    "        if top_cnt/len(y) >= self.sufficient_share:\n",
    "            self.tree[node_id] = self.__make_leaf(top_label, prob)\n",
    "            return\n",
    "        \n",
    "        n_samples, n_features = x.shape\n",
    "\n",
    "        splits = []\n",
    "        for f_id in self.get_feature_ids(n_features):\n",
    "            gvalue, threshold = self.__find_threshold(x[:, f_id], y)\n",
    "\n",
    "            if threshold is not None:\n",
    "                splits.append((f_id, threshold, gvalue))\n",
    "  \n",
    "        if len(splits) == 0:\n",
    "            self.tree[node_id] = self.__make_leaf(top_label, prob)\n",
    "            return\n",
    "        \n",
    "        best_split = min(splits, key=lambda x: x[2])\n",
    "\n",
    "        x_l, x_r, y_l, y_r = self.__div_samples(x, y, feature_id=best_split[0],threshold=best_split[1])\n",
    "        \n",
    "        if len(y_l) == 0 or len(y_r) == 0:\n",
    "            self.tree[node_id] =  self.__make_leaf(top_label, prob)\n",
    "            return\n",
    "\n",
    "        self.tree[node_id] = self.__make_non_leaf(feature_id=best_split[0],threshold=best_split[1])\n",
    "\n",
    "        self.__fit_node(x_l, y_l, 2*node_id+1, depth+1)\n",
    "        self.__fit_node(x_r, y_r, 2*node_id+2, depth+1) \n",
    "        \n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        \n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X, y=None):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./cs-training.csv', sep=',').dropna()\n",
    "df.shape\n",
    "df = df.iloc[:100000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 11)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/truv/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/truv/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x = df.as_matrix(columns=df.columns[1:])\n",
    "y = df.as_matrix(columns=df.columns[:1])\n",
    "y = y.reshape(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2,criterion='misclass')\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6999695301055908\n",
      "1.1838865280151367\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "my_clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "\n",
    "t1 = time()\n",
    "clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, используя другой критерий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/truv/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.591094970703125\n",
      "0.9253332614898682\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "my_clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "\n",
    "t1 = time()\n",
    "clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9999584268728694\n",
      "0.9999584268728694\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8905795293922009\n",
      "0.8903716637565477\n",
      "0.8923671738588177\n",
      "0.8907458219007234\n",
      "0.8928615973059494\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применить для задачи Titanic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "df_test = pd.read_csv('test.csv', index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 11)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Age'].fillna(df_train['Age'].median(), inplace = True)\n",
    "df_train['Fare'].fillna(df_train['Fare'].median(), inplace = True)\n",
    "df_train['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace = True)\n",
    "\n",
    "le_em = LabelEncoder()\n",
    "le_sex = LabelEncoder()\n",
    "df_train['Embarked'] = le.fit_transform(df_train['Embarked'])\n",
    "df_train['Sex'] = le_sex.fit_transform(df_train['Sex'])\n",
    "\n",
    "df_train.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Age'].fillna(df_test['Age'].median(), inplace = True)\n",
    "df_test['Fare'].fillna(df_test['Fare'].median(), inplace = True)\n",
    "df_test['Embarked'].fillna(df_test['Embarked'].mode()[0], inplace = True)\n",
    "\n",
    "\n",
    "df_test['Embarked'] = le.transform(df_test['Embarked'])\n",
    "df_test['Sex'] = le_sex.transform(df_test['Sex'])\n",
    "\n",
    "df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(['Survived'], axis=1).values\n",
    "y = df_train['Survived'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "my_clf = MyDecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=7, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/truv/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for train, test in gkf.split(X, y.reshape(-1,1)):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    scores.append(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6162208239595051"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for train, test in gkf.split(X, y.reshape(-1,1)):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5319881889763779"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока что,наша модель работает лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {\n",
    "        'min_samples_split': [4],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': np.arange(2, 13)\n",
    "    }, \n",
    "    {\n",
    "        'min_samples_split': [6],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': np.arange(2, 13)\n",
    "    }, \n",
    "    {\n",
    "        'min_samples_split': [8],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': np.arange(2, 13)\n",
    "    }, \n",
    "    {\n",
    "        'min_samples_split': [10],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': np.arange(2, 13)\n",
    "    }, \n",
    "    {\n",
    "        'min_samples_split': [12],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': np.arange(2, 13)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(MyDecisionTreeClassifier(), parameters, scoring='accuracy',  cv=gkf, n_jobs=-1, verbose=1, iid=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 110 candidates, totalling 770 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 484 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 770 out of 770 | elapsed:    2.9s finished\n",
      "/home/truv/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:37: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=7, random_state=42, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=MyDecisionTreeClassifier(criterion='gini', max_depth=None, max_features=None,\n",
       "             min_samples_split=2, sufficient_share=1.0),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid=[{'min_samples_split': [4], 'criterion': ['gini', 'entropy'], 'max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])}, {'min_samples_split': [6], 'criterion': ['gini', 'entropy'], 'max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])}, {'min_samples_split': [8], 'crit...'criterion': ['gini', 'entropy'], 'max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score of my classifier: 0.6184705427446568\n",
      "Best parameters of my classifier:\n",
      " {'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 6}\n"
     ]
    }
   ],
   "source": [
    "print('Best score of my classifier:', grid_search.best_score_)\n",
    "print('Best parameters of my classifier:\\n', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 110 candidates, totalling 770 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 770 out of 770 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=7, random_state=42, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=False, n_jobs=-1,\n",
       "       param_grid=[{'min_samples_split': [4], 'criterion': ['gini', 'entropy'], 'max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])}, {'min_samples_split': [6], 'criterion': ['gini', 'entropy'], 'max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])}, {'min_samples_split': [8], 'crit...'criterion': ['gini', 'entropy'], 'max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_skl = GridSearchCV(DecisionTreeClassifier(), parameters, scoring='accuracy', cv=gkf, n_jobs=-1, verbose=1, iid=False)\n",
    "grid_search_skl.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score of library classifier: 0.826033464566929\n",
      "Best parameters of library classifier:\n",
      " {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 10}\n"
     ]
    }
   ],
   "source": [
    "print('Best score of library classifier:', grid_search_skl.best_score_)\n",
    "print('Best parameters of library classifier:\\n', grid_search_skl.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После перебора параметров, модель из библиотеки показала лучший результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
